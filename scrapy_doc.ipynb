{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spiders 爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬取html，请求URL、返回URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_settings，字典，此处可设置和 settings.py 相同的属性，且会覆盖 settings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item，解析好会被传输到 pipeline 中去处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# items 字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义要从 html 中解析的字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化 ItemClass 后，可像字典一样操作 item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# piplines 管道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 item 进行清洗、确认、存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spiders 下的 custom_settings 会设置相应的 piplinesClass，其 yield 的 Item，会被传输到 pipelinesClass 中去处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process_items，每个 pipelineClass 一定包含的方法，返回 Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_spider，spider 开启时调用，一般在这里打开文件、连接数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_spider，spider 关闭时调用，一般在这里关闭文件、关闭数据库连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from_crawler，类方法，创建一个新的 pipeline 实例，返回值即这个新建的实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# settings 设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_setting 是单个爬虫定制化的设置，settings.py 是整个项目共享的配置，两者有重复的，custom_setting 会覆盖 settings.py 中的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPIDER_MODULES = ['XX.YY', 'AA.BB']，模块列表，Scrapy 从这里寻找 spiders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITEM_PIPELINES = {'XX.YY': 300, 'AA.BB': 800}, 要用的 item pipeline 字典，亦为模块级别，值为排序，小的优先执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COOKIES_ENABLED = False，请求是否带 cookie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRY_ENABLED = False，下载失败重新尝试的次数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNLOAD_TIMEOUT = A_Digit，下载超时时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER_AGENT，默认值为 Scrapy/VERSION (+https://scrapy.org)，若未被覆盖，则使用默认值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downloader middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "engine 和 downloader 之间的 hook。当 request 从 engine 传入 downloader 时，先处理 request 再传入；当 response 从 downloader 传入 engine 时，先处理 response 再传入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活一个，在 setting.py、custom_settings 配置 DOWNLOADER_MIDDLEWARES 参数即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自制一个中间件可包含 process_request、process_response、process_exeception、from_crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. process_request，每个 request 经历该中间件时都会调用的 方法。会执行多次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. process_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. process_exeception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. from_crawler，从 Crawler 对象创建一个中间件实例，必须返回一个新的中间件实例，通过 Crawler 对象可获得 settings 中配置的参数。不一定需要，只会执行一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spider middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spider 和 engine 之间的 hook。处理 spider 至 engine 的 request 和 item，以及 engine 到 spider 的 response。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自制一个中间件可包含 process_spider_input、process_spider_output、process_spider_exception、process_start_requests、from_crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. process_spider_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. process_spider_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. process_spider_exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. process_start_requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. from_crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callback，当 request 返回 response 时，会调用 callback 指向的函数，默认是 parse，也可以自定义，如果出错默认是 errback。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "errback，request 出错后 会调用的函数，此时 callback 就不会调用了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method，有 get、post、put 方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta，在 middlewares、extensions 传递给 request 的属性信息，比如 download_timeout、proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cb_kwargs，传递给 callback 函数的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url、body、headers、cookies、encoding、priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FormRequest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于处理 html 表单的情况，模拟用户登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JsonRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理 json 格式的请求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy 为每个 spider 实例提供了 logger，但也可使用自定义 logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG_ENABLE，是否开启日志，默认 True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG_ENCODING，日志使用的编码，默认 utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG_FILE，日志文件名，默认 None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG_LEVEL，会输出的最低级别，默认 DEBUG，最低级别；总共五个级别 CRITICAL、ERROR、WARNING、INFO、DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在scrapy 导入 logging 包，即可自定义输出：import logging  logging.warning('警告信息')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
